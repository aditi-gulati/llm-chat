# LLM Provider Selection
PROVIDER=ollama  # Options: ollama, openai, anthropic

# Ollama Server Configuration
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Configuration
OPENAI_API_KEY=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
OPENAI_MODEL=GPT-4o-mini

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=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
CLAUDE_MODEL=claude-3-sonnet-20240229

# Default Model
DEFAULT_MODEL=mistral

# Chat Settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9
DEFAULT_TOP_K=40
DEFAULT_NUM_PREDICT=512
DEFAULT_NUM_CONTEXT=2048

