# LLM Provider Selection
PROVIDER=ollama  # Options: ollama, openai, anthropic

# Ollama Server Configuration
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
CLAUDE_MODEL=claude-3-sonnet-20240229

# Default Model
DEFAULT_MODEL=mistral

# Chat Settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9
DEFAULT_TOP_K=40
DEFAULT_NUM_PREDICT=512
DEFAULT_NUM_CONTEXT=2048

